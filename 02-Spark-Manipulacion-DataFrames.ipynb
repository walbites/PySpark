{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5106a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "# VERSION  \tDESARROLLADOR             FECHA        DESCRIPCION\n",
    "# -------------------------------------------------------------\n",
    "#  1        Walter Albites Azarte     10/12/2021   Curso PySpark Entorno Local - Dataframe\n",
    "##########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76caa7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark-3.1.2-bin-hadoop2.7'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7d245db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "conf= pyspark.SparkConf().setAppName('SparkApp').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark=SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7457b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f415a57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----+\n",
      "|     dni|   nombre|edad|\n",
      "+--------+---------+----+\n",
      "|99999999|   Walter|  35|\n",
      "|88888888|    Susan|  30|\n",
      "|77777777|Alejandro|  12|\n",
      "|66666666|    Pedro|  30|\n",
      "|55555555|   Karina|  35|\n",
      "|44444444|     Andy|  26|\n",
      "|33333333|  Raquel\n",
      "|  45|\n",
      "|22222222|     Gian|  28|\n",
      "|11111111|     Raul|  45|\n",
      "|00000000|    Elena|  40|\n",
      "|10101010|     null|null|\n",
      "|    null|   Raquel|null|\n",
      "+--------+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Crear Dataframe Spark personas\n",
    "schemaPersona = StructType([\n",
    "    StructField(\"dni\", StringType(),True),\n",
    "    StructField(\"nombre\", StringType(),True),\n",
    "    StructField(\"edad\", IntegerType(),True)\n",
    "])\n",
    "\n",
    "dataPersona = ([(\"99999999\", \"Walter\",35),\n",
    "                (\"88888888\", \"Susan\",30),\n",
    "                (\"77777777\", \"Alejandro\",12),\n",
    "                (\"66666666\", \"Pedro\",30),\n",
    "                (\"55555555\", \"Karina\",35),\n",
    "                (\"44444444\", \"Andy\",26),\n",
    "                (\"33333333\", \" Raquel\\n\",45),\n",
    "                (\"22222222\", \"Gian\",28),\n",
    "                (\"11111111\", \"Raul\",45),\n",
    "                (\"00000000\", \"Elena\",40),\n",
    "                (\"10101010\", None, None),\n",
    "                (None,'Raquel',None)])\n",
    "\n",
    "df_personas=spark.createDataFrame(dataPersona,schema=schemaPersona)\n",
    "df_personas.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2698e7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dni: string (nullable = true)\n",
      " |-- nombre: string (nullable = true)\n",
      " |-- edad: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_personas.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e02b1a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----+\n",
      "|dni|nombre|edad|\n",
      "+---+------+----+\n",
      "|0  |1     |0   |\n",
      "+---+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Verificar si existe Saltos de Linea en las columnas\n",
    "df_personas.select([count(when( col(c).contains('\\n'), c)).alias(c) for c in df_personas.columns]).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b964fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----+\n",
      "|     dni|   nombre|edad|\n",
      "+--------+---------+----+\n",
      "|99999999|   Walter|  35|\n",
      "|88888888|    Susan|  30|\n",
      "|77777777|Alejandro|  12|\n",
      "|66666666|    Pedro|  30|\n",
      "|55555555|   Karina|  35|\n",
      "|44444444|     Andy|  26|\n",
      "|33333333|   Raquel|  45|\n",
      "|22222222|     Gian|  28|\n",
      "|11111111|     Raul|  45|\n",
      "|00000000|    Elena|  40|\n",
      "|10101010|     null|null|\n",
      "|    null|   Raquel|null|\n",
      "+--------+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Correcion si es que huniera una columna encontrada x ejemplo nombre\n",
    "df_personas=df_personas.withColumn('nombre',regexp_replace('nombre', '\\n', ''))\n",
    "df_personas.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36e3e23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----+------------------+\n",
      "|dni     |nombre   |edad|datos_personales  |\n",
      "+--------+---------+----+------------------+\n",
      "|99999999|Walter   |35  |99999999,Walter   |\n",
      "|88888888|Susan    |30  |88888888,Susan    |\n",
      "|77777777|Alejandro|12  |77777777,Alejandro|\n",
      "|66666666|Pedro    |30  |66666666,Pedro    |\n",
      "|55555555|Karina   |35  |55555555,Karina   |\n",
      "|44444444|Andy     |26  |44444444,Andy     |\n",
      "|33333333| Raquel  |45  |33333333, Raquel  |\n",
      "|22222222|Gian     |28  |22222222,Gian     |\n",
      "|11111111|Raul     |45  |11111111,Raul     |\n",
      "|00000000|Elena    |40  |00000000,Elena    |\n",
      "|10101010|null     |null|10101010          |\n",
      "|null    |Raquel   |null|Raquel            |\n",
      "+--------+---------+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# concat_ws() función de Pyspark concatena múltiples columnas de cadenas en una sola columna con un separador\n",
    "# o delimitador determinado.\n",
    "df_personas.withColumn('datos_personales', concat_ws(',',col('dni'),col('nombre'))).show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b98d0bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----+-----------------+\n",
      "|dni     |nombre   |edad|datos_personales2|\n",
      "+--------+---------+----+-----------------+\n",
      "|99999999|Walter   |35  |99999999Walter   |\n",
      "|88888888|Susan    |30  |88888888Susan    |\n",
      "|77777777|Alejandro|12  |77777777Alejandro|\n",
      "|66666666|Pedro    |30  |66666666Pedro    |\n",
      "|55555555|Karina   |35  |55555555Karina   |\n",
      "|44444444|Andy     |26  |44444444Andy     |\n",
      "|33333333| Raquel  |45  |33333333 Raquel  |\n",
      "|22222222|Gian     |28  |22222222Gian     |\n",
      "|11111111|Raul     |45  |11111111Raul     |\n",
      "|00000000|Elena    |40  |00000000Elena    |\n",
      "|10101010|null     |null|null             |\n",
      "|null    |Raquel   |null|null             |\n",
      "+--------+---------+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_personas.withColumn('datos_personales2', concat(col('dni'),col('nombre'))).show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d14ad786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|   dni_1|   dni_2|\n",
      "+--------+--------+\n",
      "|    null|    null|\n",
      "|88888888|    null|\n",
      "|    null|99999999|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Coalesce función de Pyspark Devuelve la primera columna que no es nula.\n",
    "df_documentoidentidad = spark.createDataFrame([(None, None), (88888888, None), (None, 99999999)], (\"dni_1\", \"dni_2\"))\n",
    "df_documentoidentidad.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44f56e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|     dni|\n",
      "+--------+\n",
      "|    null|\n",
      "|88888888|\n",
      "|99999999|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_documentoidentidad.select(coalesce(col(\"dni_1\"), col(\"dni_2\")).alias(\"dni\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f846a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----+\n",
      "|     dni|   nombre|edad|\n",
      "+--------+---------+----+\n",
      "|99999999|   Walter|  35|\n",
      "|88888888|    Susan|  30|\n",
      "|77777777|Alejandro|  12|\n",
      "|66666666|    Pedro|  30|\n",
      "|55555555|   Karina|  35|\n",
      "|44444444|     Andy|  26|\n",
      "|33333333|   Raquel|  45|\n",
      "|22222222|     Gian|  28|\n",
      "|11111111|     Raul|  45|\n",
      "|00000000|    Elena|  40|\n",
      "|10101010|     null|null|\n",
      "|    null|   Raquel|null|\n",
      "+--------+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_personas.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b61012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ejemplos utilizando UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b67230e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear una funcion que convierta en minusculas\n",
    "def ConvertirMinusculas(texto):\n",
    "    texto=texto.lower()\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "642740ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un UDF a apartir de una funcion de Python\n",
    "udf_convertir_misnusculas=udf(ConvertirMinusculas,StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92ca68d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una columna normalizada en minuscula con la columna nombre y curso, Saldra error al parecer lee todas las filas\n",
    "# del dataframe Los null y vacios por mas que se use la condicional\n",
    "\n",
    "#df_personasy=df_personas.withColumn(\"nombre_normalizado\",when(((col(\"nombre\").isNotNull()) & (col(\"nombre\")!=\"\")),\n",
    "#                                         udf_convertir_misnusculas(\"nombre\")).otherwise(\"\"))\n",
    "\n",
    "#df_personasy.show()\n",
    "\n",
    "# AttributeError: 'NoneType' object has no attribute 'lower'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cb272d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----+-----------+\n",
      "|     dni|   nombre|edad|nombre_temp|\n",
      "+--------+---------+----+-----------+\n",
      "|99999999|   Walter|  35|     Walter|\n",
      "|88888888|    Susan|  30|      Susan|\n",
      "|77777777|Alejandro|  12|  Alejandro|\n",
      "|66666666|    Pedro|  30|      Pedro|\n",
      "|55555555|   Karina|  35|     Karina|\n",
      "|44444444|     Andy|  26|       Andy|\n",
      "|33333333|   Raquel|  45|     Raquel|\n",
      "|22222222|     Gian|  28|       Gian|\n",
      "|11111111|     Raul|  45|       Raul|\n",
      "|00000000|    Elena|  40|      Elena|\n",
      "|10101010|     null|null|           |\n",
      "|    null|   Raquel|null|     Raquel|\n",
      "+--------+---------+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Solucion 1\n",
    "#Crear una nueva columna temporal para colocar valores vacios a los NULL\n",
    "df_personasz=df_personas.select('*',col(\"nombre\").alias(\"nombre_temp\"))\n",
    "df_personasz=df_personasz.na.fill(value=\"\",subset=[\"nombre_temp\"])\n",
    "df_personasz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98826451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----+------------------+\n",
      "|dni     |nombre   |edad|nombre_normalizado|\n",
      "+--------+---------+----+------------------+\n",
      "|99999999|Walter   |35  |walter            |\n",
      "|88888888|Susan    |30  |susan             |\n",
      "|77777777|Alejandro|12  |alejandro         |\n",
      "|66666666|Pedro    |30  |pedro             |\n",
      "|55555555|Karina   |35  |karina            |\n",
      "|44444444|Andy     |26  |andy              |\n",
      "|33333333| Raquel  |45  | raquel           |\n",
      "|22222222|Gian     |28  |gian              |\n",
      "|11111111|Raul     |45  |raul              |\n",
      "|00000000|Elena    |40  |elena             |\n",
      "|10101010|null     |null|                  |\n",
      "|null    |Raquel   |null|raquel            |\n",
      "+--------+---------+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos el filtro y utilizamos el UDF \n",
    "df_personasz=df_personasz.withColumn(\"nombre_normalizado\",\n",
    "                                    when(col(\"nombre_temp\")!=\"\",\n",
    "                                         udf_convertir_misnusculas(\"nombre_temp\")).\\\n",
    "                                         #lit(\"Con Dato\")).\n",
    "                                    otherwise(\"\")\n",
    "                                   ).drop(\"nombre_temp\")\n",
    "df_personasz.show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbd905d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solucion 2\n",
    "#Modificar la funcion cuando es None asignarle vacio\n",
    "def ConvertirMinusculas(texto):\n",
    "    if texto==None:\n",
    "        texto=\"\"\n",
    "    else:\n",
    "        texto=texto.lower()\n",
    "    return texto\n",
    "\n",
    "udf_convertir_misnusculas=udf(ConvertirMinusculas,StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44a85e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----+------------------+\n",
      "|dni     |nombre   |edad|nombre_normalizado|\n",
      "+--------+---------+----+------------------+\n",
      "|99999999|Walter   |35  |walter            |\n",
      "|88888888|Susan    |30  |susan             |\n",
      "|77777777|Alejandro|12  |alejandro         |\n",
      "|66666666|Pedro    |30  |pedro             |\n",
      "|55555555|Karina   |35  |karina            |\n",
      "|44444444|Andy     |26  |andy              |\n",
      "|33333333| Raquel  |45  | raquel           |\n",
      "|22222222|Gian     |28  |gian              |\n",
      "|11111111|Raul     |45  |raul              |\n",
      "|00000000|Elena    |40  |elena             |\n",
      "|10101010|null     |null|                  |\n",
      "|null    |Raquel   |null|raquel            |\n",
      "+--------+---------+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_personasm=df_personas.withColumn(\"nombre_normalizado\",\n",
    "                                    when(((col(\"nombre\").isNotNull()) & (col(\"nombre\")!=\"\")),\n",
    "                                         udf_convertir_misnusculas(\"nombre\")).\\\n",
    "                                    otherwise(\"\")\n",
    "                                   )\n",
    "df_personasm.show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "665b75e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_personas_x=df_personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e055de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar Columnas utilizando withColumnRenamed, Consume mucha memoria\n",
    "for column in df_personas_x.columns:\n",
    "        df_personas_x=df_personas_x.withColumnRenamed(column,'personas_' + column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48506657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+-------------+\n",
      "|personas_dni|personas_nombre|personas_edad|\n",
      "+------------+---------------+-------------+\n",
      "|99999999    |Walter         |35           |\n",
      "|88888888    |Susan          |30           |\n",
      "|77777777    |Alejandro      |12           |\n",
      "|66666666    |Pedro          |30           |\n",
      "|55555555    |Karina         |35           |\n",
      "+------------+---------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_personas_x.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8fecca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+------------+\n",
      "|persons_dni|persons_nombre|persons_edad|\n",
      "+-----------+--------------+------------+\n",
      "|   99999999|        Walter|          35|\n",
      "|   88888888|         Susan|          30|\n",
      "|   77777777|     Alejandro|          12|\n",
      "|   66666666|         Pedro|          30|\n",
      "|   55555555|        Karina|          35|\n",
      "|   44444444|          Andy|          26|\n",
      "|   33333333|        Raquel|          45|\n",
      "|   22222222|          Gian|          28|\n",
      "|   11111111|          Raul|          45|\n",
      "|   00000000|         Elena|          40|\n",
      "|   10101010|          null|        null|\n",
      "|       null|        Raquel|        null|\n",
      "+-----------+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renombrar columnas utilizando Alias, no consume mucha memoria Recomendable\n",
    "df_personas_y=df_personas.select([col(i).alias('persons_'+i) for i in df_personas.columns])\n",
    "df_personas_y.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1bf7388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----+\n",
      "|dni|nombre|edad|\n",
      "+---+------+----+\n",
      "|  1|     1|   2|\n",
      "+---+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Indentificar Columnas NULL, Nan y Vacios\n",
    "df_personas.select([count(when( (isnan(c))| (col(c).isNull()) | (col(c)==''), c)).alias(c) for c in df_personas.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc7381d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----+\n",
      "|dni|nombre|edad|\n",
      "+---+------+----+\n",
      "|0  |0     |0   |\n",
      "+---+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Verificar espacios al inicio y al final de una columna\n",
    "df_personas.select([count(when( col(c).contains('\\xa0'), c)).alias(c) for c in df_personas.columns]).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eeca785a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----+----------+\n",
      "|     dni|   nombre|edad|     fecha|\n",
      "+--------+---------+----+----------+\n",
      "|99999999|   Walter|  35|2022-07-20|\n",
      "|88888888|    Susan|  30|2022-07-20|\n",
      "|77777777|Alejandro|  12|2022-07-20|\n",
      "|66666666|    Pedro|  30|2022-07-20|\n",
      "|55555555|   Karina|  35|2022-07-20|\n",
      "|44444444|     Andy|  26|2022-07-20|\n",
      "|33333333|   Raquel|  45|2022-07-20|\n",
      "|22222222|     Gian|  28|2022-07-20|\n",
      "|11111111|     Raul|  45|2022-07-20|\n",
      "|00000000|    Elena|  40|2022-07-20|\n",
      "|10101010|     null|null|2022-07-20|\n",
      "|    null|   Raquel|null|2022-07-20|\n",
      "+--------+---------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adicionar una columna con la fecha del sistema\n",
    "df_personas.withColumn('fecha',current_date()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ee0f456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----+-----------------------+\n",
      "|dni     |nombre   |edad|fechaHora              |\n",
      "+--------+---------+----+-----------------------+\n",
      "|99999999|Walter   |35  |2022-07-20 16:29:55.372|\n",
      "|88888888|Susan    |30  |2022-07-20 16:29:55.372|\n",
      "|77777777|Alejandro|12  |2022-07-20 16:29:55.372|\n",
      "|66666666|Pedro    |30  |2022-07-20 16:29:55.372|\n",
      "|55555555|Karina   |35  |2022-07-20 16:29:55.372|\n",
      "+--------+---------+----+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adicionar una columna con la fecha y Hora  del sistema\n",
    "df_personas.withColumn(\"fechaHora\",to_timestamp(current_timestamp(),\"MM-dd-yyyy HH mm ss SSS\")).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb7821ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 16:29:56.171173\n"
     ]
    }
   ],
   "source": [
    "# Capturar la fecha y hora de Inicio de ejecucion\n",
    "from datetime import datetime\n",
    "x=str(datetime.now())\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d83ce073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/07/22\n"
     ]
    }
   ],
   "source": [
    "# fechas en Python\n",
    "import time\n",
    "print (time.strftime(\"%d/%m/%y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d1eb269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----+--------+\n",
      "|     dni|   nombre|edad|    date|\n",
      "+--------+---------+----+--------+\n",
      "|99999999|   Walter|  35|20/07/22|\n",
      "|88888888|    Susan|  30|20/07/22|\n",
      "|77777777|Alejandro|  12|20/07/22|\n",
      "|66666666|    Pedro|  30|20/07/22|\n",
      "|55555555|   Karina|  35|20/07/22|\n",
      "|44444444|     Andy|  26|20/07/22|\n",
      "|33333333|   Raquel|  45|20/07/22|\n",
      "|22222222|     Gian|  28|20/07/22|\n",
      "|11111111|     Raul|  45|20/07/22|\n",
      "|00000000|    Elena|  40|20/07/22|\n",
      "|10101010|     null|null|20/07/22|\n",
      "|    null|   Raquel|null|20/07/22|\n",
      "+--------+---------+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_personas.withColumn('date',lit(time.strftime(\"%d/%m/%y\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b866e7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|max(length(dni))|\n",
      "+----------------+\n",
      "|               8|\n",
      "+----------------+\n",
      "\n",
      "+-------------------+\n",
      "|max(length(nombre))|\n",
      "+-------------------+\n",
      "|                  9|\n",
      "+-------------------+\n",
      "\n",
      "+-----------------+\n",
      "|max(length(edad))|\n",
      "+-----------------+\n",
      "|                2|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Valores maximos de cada Columna\n",
    "for i in df_personas.columns:\n",
    "    df_personas.select(max(length(i))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9fc65e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### Join parametrizable en Funciones Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e841acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+\n",
      "|     dni| curso|precio|\n",
      "+--------+------+------+\n",
      "|99999999| Spark| 100.5|\n",
      "|99999999| Scala| 100.5|\n",
      "|99999999|  Java| 100.5|\n",
      "|88888888|Ingles|  80.9|\n",
      "|77777777|  Java|  12.5|\n",
      "+--------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Crear Dataframe Spark Cursos\n",
    "schemaCursos = StructType([\n",
    "    StructField(\"dni\", StringType(),True),\n",
    "    StructField(\"curso\", StringType(),True),\n",
    "    StructField(\"precio\", DoubleType(),True)\n",
    "])\n",
    "\n",
    "dataCurso = ([(\"99999999\", \"Spark\",100.50),\n",
    "              (\"99999999\", \"Scala\",100.50),\n",
    "              (\"99999999\", \"Java\",100.50),\n",
    "              (\"88888888\", \"Ingles\",80.90),\n",
    "              (\"77777777\", \"Java\",12.50)\n",
    "])\n",
    "\n",
    "df_cursos=spark.createDataFrame(dataCurso,schema=schemaCursos)\n",
    "df_cursos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2a7a8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----+--------+------+------+\n",
      "|     dni|   nombre|edad|     dni| curso|precio|\n",
      "+--------+---------+----+--------+------+------+\n",
      "|88888888|    Susan|  30|88888888|Ingles|  80.9|\n",
      "|99999999|   Walter|  35|99999999| Spark| 100.5|\n",
      "|99999999|   Walter|  35|99999999| Scala| 100.5|\n",
      "|99999999|   Walter|  35|99999999|  Java| 100.5|\n",
      "|77777777|Alejandro|  12|77777777|  Java|  12.5|\n",
      "+--------+---------+----+--------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def join_example(dfa,dfb):\n",
    "    dfa_whith_dfb=dfa.alias(\"a\").join(dfb.alias(\"b\"),col(\"a.dni\")==col(\"b.dni\"),how='inner')\n",
    "    return dfa_whith_dfb\n",
    "\n",
    "dfa_whith_dfb=join_example(df_personas,df_cursos)\n",
    "dfa_whith_dfb.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9719f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### Join parametrizable en Funciones Pandas to Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73db08d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dni</th>\n",
       "      <th>nombre</th>\n",
       "      <th>edad</th>\n",
       "      <th>curso</th>\n",
       "      <th>precio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99999999</td>\n",
       "      <td>Walter</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Spark</td>\n",
       "      <td>100.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99999999</td>\n",
       "      <td>Walter</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Scala</td>\n",
       "      <td>100.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99999999</td>\n",
       "      <td>Walter</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Java</td>\n",
       "      <td>100.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88888888</td>\n",
       "      <td>Susan</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Ingles</td>\n",
       "      <td>80.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77777777</td>\n",
       "      <td>Alejandro</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Java</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dni     nombre  edad   curso  precio\n",
       "0  99999999     Walter  35.0   Spark   100.5\n",
       "1  99999999     Walter  35.0   Scala   100.5\n",
       "2  99999999     Walter  35.0    Java   100.5\n",
       "3  88888888      Susan  30.0  Ingles    80.9\n",
       "4  77777777  Alejandro  12.0    Java    12.5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_personas_pandas=df_personas.toPandas()\n",
    "df_cursos_pandas=df_cursos.toPandas()\n",
    "\n",
    "def merge_example_pandas(dfa,dfb):\n",
    "    dfa_whith_dfb=dfa.merge(dfb,how='inner',on=\"dni\")\n",
    "    return dfa_whith_dfb\n",
    "\n",
    "dfa_whith_dfb_pandas=merge_example_pandas(df_personas_pandas,df_cursos_pandas)\n",
    "\n",
    "dfa_whith_dfb_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71e0e8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----+------+------+\n",
      "|     dni|   nombre|edad| curso|precio|\n",
      "+--------+---------+----+------+------+\n",
      "|99999999|   Walter|35.0| Spark| 100.5|\n",
      "|99999999|   Walter|35.0| Scala| 100.5|\n",
      "|99999999|   Walter|35.0|  Java| 100.5|\n",
      "|88888888|    Susan|30.0|Ingles|  80.9|\n",
      "|77777777|Alejandro|12.0|  Java|  12.5|\n",
      "+--------+---------+----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Convertir a dataframe de Spark\n",
    "dfa_whith_dfb_pandas_spark = spark.createDataFrame(dfa_whith_dfb_pandas)\n",
    "dfa_whith_dfb_pandas_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "957a6e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dni 11 91.66666666666666\n",
      "nombre 11 91.66666666666666\n",
      "edad 10 83.33333333333334\n"
     ]
    }
   ],
   "source": [
    "#Conteos\n",
    "total=df_personas.count()\n",
    "\n",
    "for i in df_personas.columns:\n",
    "    conteo=df_personas.select(i).filter(col(i).isNotNull()).count()\n",
    "    print(i,conteo,(conteo/total)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35589f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leer CSV para que reconozca los satos de linea\n",
    "#df_personas = spark.read.options(header='True',inferSchema='True',delimiter=',',escape='\"',quote='\"',multiLine=True).\\\n",
    "#csv(root + 'personas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59cbe968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicio Tranformar DataFrame de Pandas a Dataframe de Spark\n",
    "# Auxiliar functions\n",
    "def equivalent_type(f):\n",
    "    if f == 'datetime64[ns]': return TimestampType()\n",
    "    elif f == 'int64': return LongType()\n",
    "    elif f == 'int32': return IntegerType()\n",
    "    elif f == 'float64': return FloatType()\n",
    "    else: return StringType()\n",
    "\n",
    "def define_structure(string, format_type):\n",
    "    try: typo = equivalent_type(format_type)\n",
    "    except: typo = StringType()\n",
    "    return StructField(string, typo)\n",
    "\n",
    "# Given pandas dataframe, it will return a spark's dataframe.\n",
    "def pandas_to_spark(pandas_df):\n",
    "    columns = list(pandas_df.columns)\n",
    "    types = list(pandas_df.dtypes)\n",
    "    struct_list = []\n",
    "    for column, typo in zip(columns, types):\n",
    "        struct_list.append(define_structure(column, typo))\n",
    "        \n",
    "    p_schema = StructType(struct_list)\n",
    "    return spark.createDataFrame(pandas_df, p_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d808fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jugadores    object\n",
      "Posicion     object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jugadores</th>\n",
       "      <th>Posicion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Federer</td>\n",
       "      <td>Delantero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ronaldo</td>\n",
       "      <td>Delantero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phelps</td>\n",
       "      <td>Medio campista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Valenzuela</td>\n",
       "      <td>Defensa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Jugadores        Posicion\n",
       "0     Federer       Delantero\n",
       "1     Ronaldo       Delantero\n",
       "2      Phelps  Medio campista\n",
       "3  Valenzuela         Defensa"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creamos un DataFrame en Pandas\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({\n",
    "   'Jugadores': [\"Federer\", \"Ronaldo\", \"Phelps\", \"Valenzuela\"],\n",
    "   'Posicion': [\"Delantero\", \"Delantero\", \"Medio campista\", \"Defensa\"]\n",
    "})\n",
    "print(df1.dtypes)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "afd0a5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+\n",
      "| Jugadores|      Posicion|\n",
      "+----------+--------------+\n",
      "|   Federer|     Delantero|\n",
      "|   Ronaldo|     Delantero|\n",
      "|    Phelps|Medio campista|\n",
      "|Valenzuela|       Defensa|\n",
      "+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF1_SPARK=pandas_to_spark(df1)\n",
    "DF1_SPARK.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf8a4217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Jugadores: string (nullable = true)\n",
      " |-- Posicion: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF1_SPARK.printSchema()\n",
    "# Fin Tranformar DataFrame de Pandas a Dataframe de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "958909e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+----------------+\n",
      "|      cif|   entidad_solicitud|origen_solicitud|\n",
      "+---------+--------------------+----------------+\n",
      "|A79122305|UNIVERSIDAD EUROP...|         ACT_NAC|\n",
      "|Q2868013J|ACADEMIA DE BELLA...|         ACT_NAC|\n",
      "|G46129698|FUNDACIÓN INSTITU...|         ACT_NAC|\n",
      "+---------+--------------------+----------------+\n",
      "\n",
      "+---------+----------------+--------------------+\n",
      "|      cif|acronimo_entidad|      nombre_entidad|\n",
      "+---------+----------------+--------------------+\n",
      "|A79122305|       MATERPLAT|CENTRO NACIONAL D...|\n",
      "|A79122305|       MATERPLAT|CENTRO NACIONAL D...|\n",
      "|A79122305|       MATERPLAT|CENTRO NACIONAL D...|\n",
      "|Q2868013J|             CNE|RED DE LABORATORI...|\n",
      "|Q2868013J|             CNE|RED DE LABORATORI...|\n",
      "+---------+----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Crear Dataframe Spark Solicitudes\n",
    "schemaSolicitudes = StructType([\n",
    "    StructField(\"cif\", StringType(),True),\n",
    "    StructField(\"entidad_solicitud\", StringType(),True),\n",
    "    StructField(\"origen_solicitud\", StringType(),True)\n",
    "])\n",
    "\n",
    "dataSolicitudes = ([(\"A79122305\", \"UNIVERSIDAD EUROPEA DE MADRID SA\",\"ACT_NAC\"),\n",
    "                (\"Q2868013J\", \"ACADEMIA DE BELLAS ARTES DE SAN FERNANDO\",\"ACT_NAC\"),\n",
    "                (\"G46129698\", \"FUNDACIÓN INSTITUTO VALENCIANO DE ONCOLOGÍA\",\"ACT_NAC\")\n",
    "               ])\n",
    "\n",
    "df_solicitudes=spark.createDataFrame(dataSolicitudes,schema=schemaSolicitudes)\n",
    "df_solicitudes.show()\n",
    "\n",
    "#Crear Dataframe Spark Entidades\n",
    "schemaEntidades = StructType([\n",
    "    StructField(\"cif\", StringType(),True),\n",
    "    StructField(\"acronimo_entidad\", StringType(),True),\n",
    "    StructField(\"nombre_entidad\", StringType(),True)\n",
    "])\n",
    "\n",
    "dataEntidades = ([(\"A79122305\", \"MATERPLAT\",\"CENTRO NACIONAL DE EPIDEMIOLOGIA\"),\n",
    "              (\"A79122305\", \"MATERPLAT\",\"CENTRO NACIONAL DE EPIDEMIOLOGIA\"),\n",
    "              (\"A79122305\", \"MATERPLAT\",\"CENTRO NACIONAL DE EPIDEMIOLOGIA\"),\n",
    "              (\"Q2868013J\", \"CNE\",\"RED DE LABORATORIOS DE ALERTAS BIOLOGICAS\"),\n",
    "              (\"Q2868013J\", \"CNE\",\"RED DE LABORATORIOS DE ALERTAS BIOLOGICAS\")\n",
    "])\n",
    "\n",
    "df_entidades=spark.createDataFrame(dataEntidades,schema=schemaEntidades)\n",
    "df_entidades.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36820515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+----------------+\n",
      "|      cif|   entidad_solicitud|origen_solicitud|\n",
      "+---------+--------------------+----------------+\n",
      "|G46129698|FUNDACIÓN INSTITU...|         ACT_NAC|\n",
      "+---------+--------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF_A_B_NO_CRUZAN=df_solicitudes.join(df_entidades,on=\"cif\",how=\"anti\")\n",
    "DF_A_B_NO_CRUZAN.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "532c284a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+----------------+\n",
      "|      cif|   entidad_solicitud|origen_solicitud|\n",
      "+---------+--------------------+----------------+\n",
      "|Q2868013J|ACADEMIA DE BELLA...|         ACT_NAC|\n",
      "|Q2868013J|ACADEMIA DE BELLA...|         ACT_NAC|\n",
      "|A79122305|UNIVERSIDAD EUROP...|         ACT_NAC|\n",
      "|A79122305|UNIVERSIDAD EUROP...|         ACT_NAC|\n",
      "|A79122305|UNIVERSIDAD EUROP...|         ACT_NAC|\n",
      "+---------+--------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF_A_B_CRUZAN=df_solicitudes.alias('a').join(df_entidades.alias('b'),\n",
    "                                             col('a.cif')==col('b.cif'),\n",
    "                                             how=\"inner\"\n",
    "                                            ).select('a.*')\n",
    "DF_A_B_CRUZAN.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5964db60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- nombre_empleado: string (nullable = true)\n",
      " |-- departamento: string (nullable = true)\n",
      " |-- salario: long (nullable = true)\n",
      "\n",
      "+---------------+------------+-------+\n",
      "|nombre_empleado|departamento|salario|\n",
      "+---------------+------------+-------+\n",
      "|James          |Ventas      |3000   |\n",
      "|Michael        |Ventas      |4600   |\n",
      "|Robert         |Ventas      |4100   |\n",
      "|Maria          |Sistemas    |3000   |\n",
      "|James          |Ventas      |3000   |\n",
      "|Scott          |Sistemas    |3300   |\n",
      "|Jen            |Sistemas    |3900   |\n",
      "|Jeff           |Marketing   |3000   |\n",
      "|Kumar          |Marketing   |2000   |\n",
      "|Saif           |Ventas      |4100   |\n",
      "+---------------+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################################################### Las funciones de PySpark Window \n",
    "#operan en un grupo de filas (como marco, división) y \n",
    "# devuelven un valor único para cada fila de entrada.\n",
    "simpleData = ((\"James\", \"Ventas\", 3000), \\\n",
    "    (\"Michael\", \"Ventas\", 4600),  \\\n",
    "    (\"Robert\", \"Ventas\", 4100),   \\\n",
    "    (\"Maria\", \"Sistemas\", 3000),  \\\n",
    "    (\"James\", \"Ventas\", 3000),    \\\n",
    "    (\"Scott\", \"Sistemas\", 3300),  \\\n",
    "    (\"Jen\", \"Sistemas\", 3900),    \\\n",
    "    (\"Jeff\", \"Marketing\", 3000), \\\n",
    "    (\"Kumar\", \"Marketing\", 2000),\\\n",
    "    (\"Saif\", \"Ventas\", 4100) \\\n",
    "  )\n",
    " \n",
    "columns= [\"nombre_empleado\", \"departamento\", \"salario\"]\n",
    "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d760f22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+-------+----------+\n",
      "|nombre_empleado|departamento|salario|row_number|\n",
      "+---------------+------------+-------+----------+\n",
      "|Kumar          |Marketing   |2000   |1         |\n",
      "|Jeff           |Marketing   |3000   |2         |\n",
      "|Maria          |Sistemas    |3000   |1         |\n",
      "|Scott          |Sistemas    |3300   |2         |\n",
      "|Jen            |Sistemas    |3900   |3         |\n",
      "|James          |Ventas      |3000   |1         |\n",
      "|James          |Ventas      |3000   |2         |\n",
      "|Robert         |Ventas      |4100   |3         |\n",
      "|Saif           |Ventas      |4100   |4         |\n",
      "|Michael        |Ventas      |4600   |5         |\n",
      "+---------------+------------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "#Para realizar una operación en un grupo primero, necesitamos particionar los datos usando Window.partitionBy(),\n",
    "#y para el número de fila y la función de rango, necesitamos ordenar adicionalmente por la orderBycláusula \n",
    "#de uso de datos de partición.\n",
    "windowPartitionDepartamento  = Window.partitionBy(\"departamento\").orderBy(\"salario\")\n",
    "#row_number()La función de window se utiliza para dar el número de fila secuencial a\n",
    "#partir de 1 al resultado de cada división de wimdow.\n",
    "df.withColumn(\"row_number\",row_number().over(windowPartitionDepartamento)).orderBy('departamento').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7244fa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+-------+\n",
      "|nombre_empleado|departamento|salario|\n",
      "+---------------+------------+-------+\n",
      "|          James|      Ventas|   3000|\n",
      "|        Michael|      Ventas|   4600|\n",
      "|         Robert|      Ventas|   4100|\n",
      "|          Maria|    Sistemas|   3000|\n",
      "|          James|      Ventas|   3000|\n",
      "|          Scott|    Sistemas|   3300|\n",
      "|            Jen|    Sistemas|   3900|\n",
      "|           Jeff|   Marketing|   3000|\n",
      "|          Kumar|   Marketing|   2000|\n",
      "|           Saif|      Ventas|   4100|\n",
      "+---------------+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d503070d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+-------+--------------+\n",
      "|nombre_empleado|departamento|salario|salario_maximo|\n",
      "+---------------+------------+-------+--------------+\n",
      "|Jeff           |Marketing   |3000   |3000          |\n",
      "|Kumar          |Marketing   |2000   |3000          |\n",
      "|Maria          |Sistemas    |3000   |3900          |\n",
      "|Scott          |Sistemas    |3300   |3900          |\n",
      "|Jen            |Sistemas    |3900   |3900          |\n",
      "|James          |Ventas      |3000   |4600          |\n",
      "|Michael        |Ventas      |4600   |4600          |\n",
      "|Robert         |Ventas      |4100   |4600          |\n",
      "|James          |Ventas      |3000   |4600          |\n",
      "|Saif           |Ventas      |4100   |4600          |\n",
      "+---------------+------------+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Salario por departamento\n",
    "windowPartitionDepartamentoX  = Window.partitionBy(\"departamento\")\n",
    "df.withColumn(\"salario_maximo\",max('salario').over(windowPartitionDepartamentoX)).orderBy('departamento').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf1749e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------------------+------------------------------+--------------------+\n",
      "|departamento|lista_empleados               |lista_salario                 |lista_salario_unicos|\n",
      "+------------+------------------------------+------------------------------+--------------------+\n",
      "|Ventas      |[Robert, Michael, Saif, James]|[3000, 4600, 4100, 3000, 4100]|[4600, 3000, 4100]  |\n",
      "|Marketing   |[Kumar, Jeff]                 |[3000, 2000]                  |[3000, 2000]        |\n",
      "|Sistemas    |[Maria, Scott, Jen]           |[3000, 3300, 3900]            |[3900, 3000, 3300]  |\n",
      "+------------+------------------------------+------------------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######### collect_set, collect_list\n",
    "df.select('departamento','nombre_empleado','salario').\\\n",
    "groupBy('departamento').\\\n",
    "agg(collect_set('nombre_empleado').alias('lista_empleados'),\n",
    "    collect_list('salario').alias('lista_salario'),\n",
    "    collect_set('salario').alias('lista_salario_unicos')\n",
    "   ).show(5,False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
